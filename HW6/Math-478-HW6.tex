\documentclass[10pt]{report}

\usepackage{subcaption} % for subfigures
\usepackage{amsthm} % for QED
%\usepackage{algpseudocode} % for pseudo-code
\usepackage{mathtools} % for delimiter

\usepackage{listings} % for code
\lstset
{
	language=Matlab,
	frame=single,
	basicstyle=\footnotesize,
	captionpos=b,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=4,
	breaklines=true,
	breakatwhitespace=false,
}

\usepackage{float} % for figure [H]
\usepackage{booktabs} % for tabular
\usepackage{caption} % for \caption*
\usepackage[export]{adjustbox} % for valign=t
\usepackage{array} % for column type m
\usepackage{verbatim}
\usepackage{graphicx}
\graphicspath{ {imgs/} }
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}

%%%%%% Pagination
\setlength{\topmargin}{-.3 in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textheight}{9.in}
\setlength{\textwidth}{6.5in}

%Title page
\newcommand{\hwTitle}{Homework \#6}
\newcommand{\hwCourse}{Numerical Differential Equations/Computational Mathematics II}
\newcommand{\hmwkClassInstructor}{Professor Shuwang Li}

\title{
	\vspace{2in}
	\textmd{\textbf{\hwCourse\\\hwTitle}}\\
	\vspace{0.3in}\large{\textit{\hmwkClassInstructor}}
	\vspace{3in}
}

%\title{Homework 1}
\author{\textbf{Zhihao Ai}}
\date{}

%Header setting. 
\pagestyle{fancy}
\fancyhead[L]{Zhihao Ai}
\fancyhead[C]{Math 478}
\fancyhead[R]{Homework 6}
%%%%%%

%Global setting.
%\everymath{\displaystyle}
\setlength\parindent{0pt}

%Custom general commands.
\newcommand{\ds}{\displaystyle}
\newcommand{\ts}{\textstyle}
\newcommand{\f}[1] {f\left(#1\right)}
\newcommand{\eva}[2] {\left. #1 \right|_{#2}}
\newcommand{\dintt}[4] {\int_{#1}^{#2} #3 d#4}

\newcolumntype{N}{ >$ c <$}
\newcolumntype{M}[1]{>{\centering\arraybackslash $}m{#1}<{$}}

\newcommand{\abs}[1] {\left| #1 \right|}

\DeclarePairedDelimiter\autoparen{(}{)}
\newcommand{\pa}[1]{\autoparen*{#1}}
\DeclarePairedDelimiter\autodvert{\Vert}{\Vert}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\newcommand{\norm}[1]{\autodvert*{#1}}

\begin{document}

\maketitle

\section*{Question 1}
% Fundamental concepts on error control..
\begin{enumerate}
	\item 
	(Problem 6.1) Find the error constants for the Adams-Bashforth method (2.7) and for Adams-Moulton methods with $s = 2, 3$.
	
	3-step Adams-Bashforth: $y_{n+3} = y_{n+2} + h\pa{ \frac{23}{12}f(t_{n+2}, y_{n+2}) - \frac{4}{3}f(t_{n+1}, y_{n+1}) + \frac{5}{12}f(t_{n}, y_{n})}$
	\[
	\rho(w) = w^3 - w^2,\quad \sigma(w) = \frac{23}{12}w^2 - \frac{4}{3}w + \frac{5}{12}
	\]
	Let $x=w-1$,
	\begin{align*}
	\rho(w) - \sigma(w) \ln{w}
	&= x(x+1)^2 - \pa{\frac{23}{12}x^2 + \frac{5}{2}x + 1} \pa{x-\frac{1}{2}x^2 + \frac{1}{3}x^3 + \cdots}\\
	&= \frac{3}{8}x^4 + O(x^5)
	\end{align*}
	Therefore the error constant for three-step Adams-Bashforth is $\frac{3}{8}$.
	
	2-step Adams-Moulton: $y_{n+1} = y_{n} + h\pa{ \frac{1}{2}f(t_{n+1}, y_{n+1}) + \frac{1}{2}f(t_{n}, y_{n})}$
	\[
	\rho(w) = w - 1,\quad \sigma(w) = \frac{1}{2}w + \frac{1}{2}
	\]
	Let $x=w-1$,
	\begin{align*}
	\rho(w) - \sigma(w) \ln{w}
	&= x - \pa{\frac{1}{2}x + 1} \pa{x-\frac{1}{2}x^2 + \frac{1}{3}x^3 + \cdots}\\
	&= -\frac{1}{12}x^3 + O(x^4)
	\end{align*}
	Therefore the error constant for two-step Adams-Moulton is $-\frac{1}{12}$.
	
	3-step Adams-Moulton: $y_{n+2} = y_{n+1} + h\pa{ \frac{5}{12}f(t_{n+2}, y_{n+2}) + \frac{2}{3}f(t_{n+1}, y_{n+1}) - \frac{1}{12}f(t_{n}, y_{n})}$
	\[
	\rho(w) = w^2 - w,\quad \sigma(w) = \frac{5}{12}w^2 + \frac{2}{3}w - \frac{1}{12}
	\]
	Let $x=w-1$,
	\begin{align*}
	\rho(w) - \sigma(w) \ln{w}
	&= x(x+1) - \pa{\frac{5}{12}x^2 + \frac{3}{2}x + 1} \pa{x-\frac{1}{2}x^2 + \frac{1}{3}x^3 + \cdots}\\
	&= -\frac{1}{24}x^4 + O(x^5)
	\end{align*}
	Therefore the error constant for three-step Adams-Bashforth is $-\frac{1}{24}$.
	
	\item 
	(Problem 6.2) Prove that the error constant of the $s$-step backward differentiation formula is $-\beta/(s + 1)$, where $\beta$ was defined in (2.14).
	
	For a BDF, we have
	\[
	\rho(w) = \beta \sum_{m=1}^{s} \frac{1}{m} w^{s-m} (w-1)^m,\quad \sigma(w) = \beta w^s
	\]
	Let $x = w - 1$,
	\begin{align*}
		\rho(w) - \sigma(w) \ln{w}
		&= \beta \sum_{m=1}^{s} \frac{1}{m} w^{s-m} (w-1)^m - \beta w^s \ln{w}\\
		&= \beta \pa{\sum_{m=1}^{s} \frac{1}{m} (x+1)^{s-m} x^m - (x+1)^s (x-\frac{1}{2}x^2 + \frac{1}{3}x^3 - \frac{1}{4}x^4 + \cdots)}
	\end{align*}
	Since $s$-step BDF is of order $s$, the terms $x^k, k=1,2,\dots,s$ on the RHS cancel out. The error constant equals the coefficient for $x^{s+1}$, which is
	\[
	-\sum_{k=0}^{s}\binom{s}{k} \frac{(-1)^k}{k+1} = -\frac{1}{s+1}
	\]
	Then we have
	\[
	\rho(w) - \sigma(w) \ln{w} = -\frac{\beta}{s+1}(w-1)^{s+1} + O(\abs{w-1}^{s+2})
	\]
	Therefore the error constant of the $s$-step backward differentiation formula is $-\beta/(s + 1)$.
	
	\item 
	(Problem 6.4) Prove that the embedded RK pair
	\[
	\renewcommand{\arraystretch}{1.2}
	\begin{array}{c|ccc}
	0 &&&\\
	\frac{1}{2} & \frac{1}{2} &&\\
	1 & -1 & 2 &\\ \hline
	& 0 & 1 &\\ \hline
	& \frac{1}{6} & \frac{2}{3} & \frac{1}{6}
	\end{array}
	\]
	combines a second-order and a third-order method.
	
	For the tableau of RK2,
	\begin{align*}
		y(t_{n+1})
		&= y(t_n + h)\\
		&= y(t_n) + hy'(t_n) + \frac{1}{2}h^2y''(t_n) + O(h^3)\\
		&= y(t_n) + hf + \frac{1}{2}h^2(f_t + f_y f) + O(h^3)\\
		y_{n+1} 
		&= y_n + hf\pa{t_n + \frac{1}{2}h, y_n + \frac{1}{2}hf}\\
		&= y(t_n) + h(f + \frac{1}{2}hf_t + \frac{1}{2}hf_yf + O(h^2))\\
		&= y(t_n) + hf + \frac{1}{2}h^2(f_t + f_y f) + O(h^3)
	\end{align*}
	Therefore the RK2 method is second-order.
	For the tableau of RK3, consider $y'=f(y)$ and we have
	\begin{align*}
	y(t_{n+1})
	&= y(t_n + h)\\
	&= y(t_n) + hy'(t_n) + \frac{1}{2}h^2y''(t_n) + \frac{1}{6}h^3y'''(t_n) + O(h^4)\\
	&= y(t_n) + hf + \frac{1}{2}h^2f_y f + \frac{1}{6}h^3\pa{f_{yy}f^2 + f_y^2f} + O(h^4)\\
	k_1 
	&= f\\
	k_2
	&= f(y_n + \frac{1}{2}hf)\\
	&= f + \frac{1}{2}h f_y f + \frac{1}{8}h^2 f_{yy} f^2 + O(h^3)\\
	k_3
	&= f\pa{y_n - hf + 2h\pa{f + \frac{1}{2}h f_y f + \frac{1}{8}h^2 f_{yy} f^2 + O(h^3)}}\\
	&= f\pa{y_n + hf + h^2f_yf + O(h^3)}\\
	&= f+hf_yf + h^2 f_y^2 f + \frac{1}{2}h^2 f_{yy}f^2 + O(h^3)\\
	y_{n+1}
	&= y_n + h\pa{\frac{1}{6}f + \frac{2}{3}\pa{f + \frac{1}{2}h f_y f + \frac{1}{8}h^2 f_{yy} f^2 + O(h^3)} + \frac{1}{6}\pa{f+hf_yf + h^2 f_y^2 f + \frac{1}{2}h^2 f_{yy}f^2 + O(h^3)}}\\
	&= y(t_n) + hf + \frac{1}{2}h^2f_y f + \frac{1}{6}h^3\pa{f_{yy}f^2 + f_y^2f} + O(h^4)
	\end{align*}
	Therefore the RK3 method is third-order. Hence the embedded RK pair combines a second-order and a third-order method.
\end{enumerate}

\section*{Computer Assignment}
Consider a linear BVP: $y'' = y - x$ on $0<x<1$ and $y(0)=0, y(1)=0$. The exact solution to this problem is $y(x) = x + \frac{e}{e^2-1}(e^{-x}-e^x)$.
\begin{enumerate}
	\item [(a)]
	Implement the linear shooting method to solve the problem using 10 subintervals. Compute the numerical errors for each node point.
	\lstinputlisting{shooting.m}
	\begin{table}[H]
		\centering
		\begin{tabular}{*{4}{N}} 
			\toprule
			x & u(x) & y(x) & \abs{u(x)-y(x)}\\ \midrule
			0.0 & 0.000000 & 0.000000 & 0.000000\\
			0.1 & 0.017353 & 0.014766 & 0.002587\\
			0.2 & 0.033704 & 0.028680 & 0.005025\\
			0.3 & 0.048040 & 0.040878 & 0.007162\\
			0.4 & 0.059328 & 0.050483 & 0.008845\\
			0.5 & 0.066505 & 0.056591 & 0.009915\\
			0.6 & 0.068467 & 0.058260 & 0.010207\\
			0.7 & 0.064057 & 0.054507 & 0.009550\\
			0.8 & 0.052055 & 0.044295 & 0.007760\\
			0.9 & 0.031164 & 0.026518 & 0.004646\\
			1.0 & 0.000000 & 0.000000 & 0.000000\\
			\bottomrule
		\end{tabular}
		\caption*{Numerical errors for shooting method}
	\end{table}
	
	\item [(b)]
	Implement the finite difference method to solve the problem using 10 subintervals. Compute the numerical errors for each node point.
	\lstinputlisting{fd.m}
	\begin{table}[H]
		\centering
		\begin{tabular}{*{4}{N}} 
			\toprule
			x & u(x) & y(x) & \abs{u(x)-y(x)}\\ \midrule
			0.0 & 0.000000 & 0.000000 & 0.000000\\
			0.1 & 0.014755 & 0.014766 & 0.000011\\
			0.2 & 0.028658 & 0.028680 & 0.000021\\
			0.3 & 0.040848 & 0.040878 & 0.000031\\
			0.4 & 0.050446 & 0.050483 & 0.000038\\
			0.5 & 0.056548 & 0.056591 & 0.000043\\
			0.6 & 0.058216 & 0.058260 & 0.000044\\
			0.7 & 0.054466 & 0.054507 & 0.000042\\
			0.8 & 0.044260 & 0.044295 & 0.000034\\
			0.9 & 0.026498 & 0.026518 & 0.000021\\
			1.0 & 0.000000 & 0.000000 & 0.000000\\
			\bottomrule
		\end{tabular}
		\caption*{Numerical errors for finite difference method}
	\end{table}

	\item [(c)]
	Comment on what you get in (a) and (b).
	
	The numerical errors of the finite difference method are much smaller than those of the shooting method. Besides, in this case, less computation is required for finite difference method than that for shooting method.
	
	\item [(d)]
	Suppose we are solving a nonlinear BVP, what changes are you going to make to the routines you developed in (a) and (b)?
	
	For shooting method, we will need to use iterations like secant method or Newton's method to get the correct initial slope. Finite difference method also needs a great amount of iterations to solve the equations.
\end{enumerate}

\end{document}
